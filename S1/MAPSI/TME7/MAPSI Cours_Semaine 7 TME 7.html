<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=windows-1252">
	<title>MAPSI Cours/Semaine 7 TME 7</title>
	<link href="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/base.html" rel="stylesheet" type="text/css">
	<script type="text/javascript">g_DefaultStyle="fixed blue";</script>
	<script type="text/javascript" src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/app.js"></script>
<!--[if IE]>
<link href="http://webia.lip6.fr/~mapsi/pub/skins/skittlish/base_ie.css" rel="stylesheet" type="text/css" />
<![endif]-->
<!--HTMLHeader--><style type="text/css"><!--
.subpage h1, h1.subpage { margin:0px; margin-top:1.2em; margin-bottom:8px; 
    color: #006633;
	font-size: 150%; }
p.subpage { float: right; }
.editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }
#siteheader .sitetitle a{height:0px; background: url(http://example.com/mylogo.gif) left top no-repeat} #siteheader .sitetitle a, #siteheader .sitetag{padding-left: 0px} #siteheader .sitetag{margin-top: 44px}
  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }
/**
 * GeSHi Dynamically Generated Stylesheet
 * --------------------------------------
 * Dynamically generated stylesheet for python
 * CSS class: , CSS id: 
 * GeSHi (C) 2004 - 2007 Nigel McNie, 2007 - 2008 Benny Baumann
 * (http://qbnz.com/highlighter/ and http://geshi.org/)
 * --------------------------------------
 */
.python .de1, .python .de2 {font-family: monospace; font-weight: normal;}
.python  {font-family:monospace;}
.python .imp {font-weight: bold; color: red;}
.python li, .python .li1 {font-family: monospace; color: black; font-weight: normal;}
.python .ln {width:1px;text-align:right;margin:0;padding:0 2px;vertical-align:top;}
.python .li2 {font-weight: bold;}
.python .kw1 {color: #ff7700;font-weight:bold;}
.python .kw2 {color: #008000;}
.python .kw3 {color: #dc143c;}
.python .kw4 {color: #0000cd;}
.python .co1 {color: #808080; font-style: italic;}
.python .coMULTI {color: #808080; font-style: italic;}
.python .es0 {color: #000099; font-weight: bold;}
.python .br0 {color: black;}
.python .sy0 {color: #66cc66;}
.python .st0 {color: #483d8b;}
.python .nu0 {color: #ff4500;}
.python .me1 {color: black;}
.python .ln-xtra, .python li.ln-xtra, .python div.ln-xtra {background-color: #ffc;}
.python span.xtra { display:block; }

.sourceblocklink {
  text-align: right;
  font-size: smaller;
}
.sourceblocktext {
  padding: 0.5em;
  border: 1px solid #808080;
  color: #000000;
  background-color: #fafafa;
}
.sourceblocktext div {
  font-family: monospace;
  font-size: small;
  line-height: 1;
  height: 1%;
}
.sourceblocktext div.head,
.sourceblocktext div.foot {
  font: italic medium serif;
  padding: 0.5em;
}

--></style><script type="text/javascript" src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/MathJax.js">MathJax.Hub.Config({
    extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: { inlineMath: [ ['{\$','\$}'] ], displayMath: [ ['{\$\$','\$\$}'] ] } });</script><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style>  <meta name="robots" content="index,follow">

<style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; color: #666666}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_Menu_Close {position: absolute; width: 31px; height: 31px; top: -15px; left: -15px}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style></head>

<body class="fixed blue"><div style="display: none;" id="MathJax_Message"></div>
<script type="text/javascript">
//<![CDATA[
	loadPreferences()
//]]>
</script>

	<div id="wrapper">
		<div id="header" class="clearfix">
			<div id="siteheader" class="clearfix">
				<!--PageHeaderFmt-->
				<h1 class="sitetitle"><a class="urllink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php" rel="nofollow">MAPSI</a></h1>
<div class="sitetag">Modèles et Algorithmes de Probabilités et Statistiques pour l'Informatique
</div>

				<!--/PageHeaderFmt-->
			</div>

			<!--PageTabsFmt-->
			<div id="menu">
				
			</div>
			<!--/PageTabsFmt-->
		</div>

		<div id="contentwrapper" class="clearfix">
			<div id="content">
				<div id="innerwrapper">
					<!--PageTitleGroupFmt-->
					<a href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours" class="pagegroup">Cours</a>
					<!--/PageTitleGroupFmt-->
					<!--PageTitleFmt--><!--/PageTitleFmt-->

					<!--PageText-->
<div id="wikitext">
<div class="vspace"></div><h2 style="background-color: #e6d8c0;">Partie obligatoire</h2>
<div class="vspace"></div><h1>TME 7: MMC et reconnaissance de lettres</h1>
<p class="vspace">La base de données est la même que dans la séance précédente:<br><a class="urllink" href="http://webia.lip6.fr/%7Emapsi/uploads/Cours/TME6_lettres.pkl" rel="nofollow"> TME6_lettres.pkl</a>
</p>
<p class="vspace">Les mécanismes de discrétisation et de tracé sont donc les mêmes (cf <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine6TME6">semaine 6</a>)
</p>
<div class="vspace"></div>
<div class="sourceblock " id="sourceblock1">
  <div class="sourceblocktext"><div class="python"><span class="kw1">import</span> numpy <span class="kw1">as</span> np<br>
<span class="kw1">import</span> matplotlib.<span class="me1">pyplot</span> <span class="kw1">as</span> plt<br>
<span class="co1"># truc pour un affichage plus convivial des matrices numpy</span><br>
np.<span class="me1">set_printoptions</span><span class="br0">(</span>precision<span class="sy0">=</span><span class="nu0">2</span><span class="sy0">,</span> linewidth<span class="sy0">=</span><span class="nu0">320</span><span class="br0">)</span><br>
plt.<span class="me1">close</span><span class="br0">(</span><span class="st0">'all'</span><span class="br0">)</span><br>
<br>
data <span class="sy0">=</span> pkl.<span class="me1">load</span><span class="br0">(</span><span class="kw2">file</span><span class="br0">(</span><span class="st0">"ressources/lettres.pkl"</span><span class="sy0">,</span><span class="st0">"rb"</span><span class="br0">)</span><span class="br0">)</span><br>
X <span class="sy0">=</span> np.<span class="kw3">array</span><span class="br0">(</span>data.<span class="me1">get</span><span class="br0">(</span><span class="st0">'letters'</span><span class="br0">)</span><span class="br0">)</span><br>
Y <span class="sy0">=</span> np.<span class="kw3">array</span><span class="br0">(</span>data.<span class="me1">get</span><span class="br0">(</span><span class="st0">'labels'</span><span class="br0">)</span><span class="br0">)</span><br>
<br>
nCl <span class="sy0">=</span> <span class="nu0">26</span></div></div>
  <div class="sourceblocklink"><a href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=sourceblock&amp;num=1" type="text/plain">[$[Get Code]]</a></div>
</div>

<div class="vspace"></div><h2><span style="color: blue;"> Passage au MMC</span></h2>
<p>Le but de la séance est de mettre en oeuvre un modèle de Markov caché
 (MMC). Pour cela, nous allons développer les algorithmes vus en TD.
</p>
<div class="vspace"></div><h3><span style="color: purple;"> Apprentissage d'un modèle connaissant les états</span></h3>
<h4>Hypothèse Gauche-Droite</h4>
<p>On fait l'hypothèse que les états sont connus... Alors que ce n'est 
pas le cas. Mais il existe des stratégies simples (et parfois efficaces)
 pour attribuer arbitrairement des états sur les chaines.
La plus classique est l'hypothèse gauche-droite, qui est bien adaptée 
aux signaux courts et non périodiques:
</p>
<div class="vspace"></div><ul><li>On définit le nombre d'états N
</li><li>On découpe chaque série d'observations en N portions à peu près égales
</li><li>On affecte l'état 0 au début, puis on incrémente jusqu'à l'état N pour la dernière portion de la chaine
</li></ul><p class="vspace">Sur un exemple:
</p>
<div class="vspace"></div><pre>  X0 = [ 1.  9.  8.  8.  8.  8.  8.  9.  3.  4.  5.  6.  6.  6.  7.  7.  8.  9.  0.  0.  0.  1.  1.]
  S0 = [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  3.]
</pre><p class="vspace">Au niveau de la mise en oeuvre, vous définirez la méthode <code>def initGD(X,N):</code> qui prend un ensemble de séquences d'observations et qui retourne l'ensemble des séquences d'états. Pour chaque séquence <code>x</code>, vous pouvez utiliser:
</p>
<div class="sourceblock " id="sourceblock2">
  <div class="sourceblocktext"><div class="python">np.<span class="me1">floor</span><span class="br0">(</span>np.<span class="me1">linspace</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span>N-<span class="nu0">.00000001</span><span class="sy0">,</span><span class="kw2">len</span><span class="br0">(</span>x<span class="br0">)</span><span class="br0">)</span><span class="br0">)</span></div></div>
  <div class="sourceblocklink"><a href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=sourceblock&amp;num=2" type="text/plain">[$[Get Code]]</a></div>
</div>

<div class="vspace"></div><h4>Apprentissage</h4>
<div style="text-align: center;">  <img src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/mmc.png" alt="" title="" width="600px"></div>
<p class="vspace">Etant donné la structure d'un MMC:
</p><ul><li>les observations n'influencent pas les états: les matrices {$\Pi, A$} s'obtiennent comme dans un modèle de Markov simple (cf <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine6TME6">semaine 6</a>)
</li><li>chaque observation ne dépend que de l'état courant
</li></ul><p class="vspace">La nature des données nous pousse à 
considérer des lois de probabilités discrètes quelconques pour les 
émissions. L'idée est donc de procéder par comptage en définissant la 
matrice {$B$} comme suit:
</p><ul><li>K colonnes (nombre d'observations), N lignes (nombre d'états)
</li><li>Chaque ligne correspond à une loi d'émission pour un état (ie, chaque ligne somme à 1)
</li></ul><p>Ce qui donne l'algorithme:
</p><ol><li>{$b_{ij}$} = comptage des émissions depuis l'état {$s_i$} vers l'observation {$x_j$}
</li><li>normalisation des lignes de {$B$}
</li></ol><p class="vspace">Donner le code de la fonction <code>def learnHMM(allX, allS, N, K):</code> qui apprend un modèle à partir d'un ensemble de couples (seq. d'observations, seq. d'états)
</p>
<p class="vspace"><strong>Variante stabilisée</strong>: afin d'éviter 
les transitions à probabilité nulle et de régulariser l'ensemble du 
système, il est intéressant d'initialiser les matrices de transition à 
une valeur non nulle. Cette initialisation <em>spéciale</em> peut être faite de manière optionnelle en utilisant les arguments par défaut de python:
</p>
<div class="vspace"></div>
<div class="sourceblock " id="sourceblock3">
  <div class="sourceblocktext"><div class="python"><span class="kw1">def</span> learnHMM<span class="br0">(</span>allx<span class="sy0">,</span> allq<span class="sy0">,</span> N<span class="sy0">,</span> K<span class="sy0">,</span> initTo0<span class="sy0">=</span><span class="kw2">False</span><span class="br0">)</span>:<br>
&nbsp; &nbsp; <span class="kw1">if</span> initTo0:<br>
&nbsp; &nbsp; &nbsp; &nbsp; A <span class="sy0">=</span> np.<span class="me1">zeros</span><span class="br0">(</span><span class="br0">(</span>N<span class="sy0">,</span>N<span class="br0">)</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; B <span class="sy0">=</span> np.<span class="me1">zeros</span><span class="br0">(</span><span class="br0">(</span>N<span class="sy0">,</span>K<span class="br0">)</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; Pi <span class="sy0">=</span> np.<span class="me1">zeros</span><span class="br0">(</span>N<span class="br0">)</span><br>
&nbsp; &nbsp; <span class="kw1">else</span>:<br>
&nbsp; &nbsp; &nbsp; &nbsp; eps <span class="sy0">=</span> <span class="nu0">1e-8</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; A <span class="sy0">=</span> np.<span class="me1">ones</span><span class="br0">(</span><span class="br0">(</span>N<span class="sy0">,</span>N<span class="br0">)</span><span class="br0">)</span>*eps<br>
&nbsp; &nbsp; &nbsp; &nbsp; B <span class="sy0">=</span> np.<span class="me1">ones</span><span class="br0">(</span><span class="br0">(</span>N<span class="sy0">,</span>K<span class="br0">)</span><span class="br0">)</span>*eps<br>
&nbsp; &nbsp; &nbsp; &nbsp; Pi <span class="sy0">=</span> np.<span class="me1">ones</span><span class="br0">(</span>N<span class="br0">)</span>*eps<br>
...</div></div>
  <div class="sourceblocklink"><a href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=sourceblock&amp;num=3" type="text/plain">[$[Get Code]]</a></div>
</div>

<p class="vspace"><span style="color: red;"> Validation sur les séquences de la classe A:</span>
</p>
<div class="vspace"></div><pre>  K = 10 # discrétisation (=10 observations possibles)
  N = 5  # 5 états possibles (de 0 à 4 en python) 
  # Xd = angles observés discrétisés

  Pi, A, B = learnHMM(Xd[Y=='a'],q[Y=='a'],N,K)

  Pi=[ 1.  0.  0.  0.  0.]

  A=[[ 0.79  0.21  0.    0.    0.  ]
     [ 0.    0.76  0.24  0.    0.  ]
     [ 0.    0.    0.77  0.23  0.  ]
     [ 0.    0.    0.    0.76  0.24]
     [ 0.    0.    0.    0.    1.  ]]

  B=[[ 0.06  0.02  0.    0.    0.    0.    0.    0.04  0.49  0.4 ]
     [ 0.    0.04  0.    0.13  0.09  0.13  0.02  0.09  0.41  0.09]
     [ 0.    0.    0.    0.02  0.12  0.5   0.31  0.04  0.    0.  ]
     [ 0.07  0.    0.    0.    0.    0.    0.26  0.33  0.2   0.15]
     [ 0.73  0.12  0.    0.    0.    0.    0.    0.02  0.02  0.12]]
</pre><div class="vspace"></div><h3><span style="color: purple;"> Viterbi (en log)</span></h3>
<p>Rappels:
</p><ul><li>Viterbi sert à estimer la séquence d'états la plus probable étant donnés les observations et le modèle.
</li><li>Viterbi peut servir à approximer la probabilité de la séquence d'observation étant donné le modèle.
</li></ul><p class="vspace">1. Initialisation (avec les indices à 0 en python):
{$$\begin{array}{ccccccccc}
 \delta_{0} (i) &amp;=&amp; \log \pi_{i} +\log b_{i} (x_{1}) \\
 \Psi_{0}(i) &amp;=&amp; -1 \mbox{ Note: -1 car non utilisé normalement}
\end{array}$$}
2. Récursion:
{$$ \begin{array}{ccccccccc}
\delta_{t} (j) &amp;=&amp;\displaystyle \left[\max_{i} \delta_{t-1}(i) + \log a_{ij}\right] + \log b_{j}(x_{t}) \\ 
\Psi_{t}(j) &amp;=&amp;\displaystyle \arg\max_{i\in [1,\ N]}  \delta_{t-1} (i) + \log a_{ij}
\end{array}$$}
3. Terminaison (indices à {$T-1$} en python)
{$$ S^{\star} = \max_{i} \delta_{T-1}(i)$$}
4. Chemin
{$$\begin{array}{ccccccccc}
s_{T-1}^{\star} &amp; = &amp;\displaystyle \arg\max_{i} \delta_{T-1}(i) \\ 
s_{t}^{\star} &amp; = &amp; \displaystyle \Psi_{t+1}(s_{t+1}^{\star})
\end{array}$$}
</p>
<p class="vspace">L'estimation de {$\log  p(x_0^{T-1} |&nbsp;\lambda)$} 
est obtenue en cherchant la plus grande probabilité dans la dernière 
colonne de {$\delta$}.<br>Donner le code de la méthode <code>def viterbi(x,Pi,A,B):</code>
</p>
<p class="vspace"><span style="color: red;"> validation en utilisant le modèle précédent {$\lambda_A$} (mêmes valeurs de N et K):</span>
</p>
<div class="vspace"></div><pre>  s_est, p_est = viterbi(Xd[0], Pi, A, B)
  s_est = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  2.  2.  2.  2.  2.  3.  3.  3.  3.  4.  4.  4.  4.  4.]
  p_est = -38.0935655456
</pre><div class="vspace"></div><h3><span style="color: purple;"> [OPT] Probabilité d'une séquence d'observation</span></h3>
<p>En fonction de votre vitesse d'avancement, coder la version 
{$\alpha$} de l'estimation (exacte) des probabilités d'une séquence 
d'observations.
Comparer avec l'approximation estimée précédemment (le résultat attendu 
est-il plus ou moins élevé avec la procédure exacte?).
</p>
<p class="vspace"><span style="color: red;"> validation</span>
</p>
<div class="vspace"></div><pre>  p =  calc_log_pobs_v2(Xd[0],Pi, A, B)
  p = -34.8950422805
</pre><div class="vspace"></div><h3><span style="color: purple;"> Apprentissage complet (Baum-Welch simplifié)</span></h3>
<p>En utilisant la procédure de Baum-Welch simplifiée vue en TD et 
rappelée ci-dessous, proposer un code pour apprendre les modèles 
correspondant aux 26 lettres de l'alphabet.
</p>
<p class="vspace"><strong>Baum-Welch simplifié:</strong>
</p><ol><li>Initialisation des états cachés arbitraire (eg méthode gauche-droite)
</li><li>Tant que <em>critère de convergence</em> non atteint
<ol><li>Apprentissage des modèles {$\lambda_{lettre}=\{\Pi, A, B\}$}
</li><li>Estimation des états cachés par Viterbi
</li></ol></li></ol><p class="vspace">Le critère de convergence sera la vraisemblance.
</p><ul><li>A chaque itération {$k$} et pour toutes les lettres {$lettre$}, calculer pour l'ensemble des séquences d'observation : 
</li></ul><p>{$$\log\mathcal L^k = \sum_{lettre}\sum_i \log p(\mathbf x_i^{lettre} | \lambda_{lettre}^k)$$}
</p><ul><li>Lorsque la vraisemblance n'évolue plus (ie 
{$\frac{\log\mathcal L^k - \log\mathcal L^{k+1}}{\log\mathcal L^k} &lt; 
1e-4$}), sortir de la boucle de mise à jour.
<div class="vspace"></div></li><li>Donner l'implémentation de la méthode d'apprentissage
</li><li>Tracer la courbe de l'évolution de la vraisemblance au cours des itérations
</li></ul><div class="vspace"></div><h3><span style="color: purple;"> Evaluation des performances</span></h3>
<p>Comme dans la séance précédente, il faut trouver un moyen d'évaluer 
les performances sans biaiser les résultats... Nous utilisons la même 
procédure.
</p><ul><li>Récupérer la méthode <code>separeTrainTest(y, pc)</code> documentée lors de la séance précédente.
</li><li>Apprendre les modèles sur les échantillons d'apprentissage.
</li><li>Evaluer les performances sur les données de test.
</li></ul><p class="vspace">Le code de cette partie est grossièrement identique à la séance passée. Pour plus de détails : <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine6TME6">semaine 6</a>
Comme lors de la semaine précédente, dessiner la matrice de confusion pour détecter les lettres faciles/difficiles à distinguer.
</p>
<div class="vspace"></div><h2 style="background-color: #e6d8c0;">Partie optionnelle</h2>
<h3><span style="color: purple;"> Génération de lettres</span></h3>
<p>Comme dans le TME précédent, proposer une procédure de génération de lettres. 
</p><ul><li>Donner le code de <code>generateHMM</code> qui génère une 
séquence d'observations (et une séquence d'états) à partir des sommes 
cumulées des modèles de lettres (cf usage ci-dessous)
</li><li>Faire tourner le code suivant qui réalise la génération de n échantillon pour nClred classes de lettres
</li></ul><div class="vspace"></div>
<div class="sourceblock " id="sourceblock4">
  <div class="sourceblocktext"><div class="python"><br>
<span class="co1"># affichage d'une lettre (= vérification bon chargement)</span><br>
<span class="kw1">def</span> tracerLettre<span class="br0">(</span>let<span class="br0">)</span>:<br>
&nbsp; &nbsp; a <span class="sy0">=</span> -let*np.<span class="me1">pi</span>/<span class="nu0">180</span><span class="sy0">;</span><br>
&nbsp; &nbsp; coord <span class="sy0">=</span> np.<span class="kw3">array</span><span class="br0">(</span><span class="br0">[</span><span class="br0">[</span><span class="nu0">0</span><span class="sy0">,</span> <span class="nu0">0</span><span class="br0">]</span><span class="br0">]</span><span class="br0">)</span><span class="sy0">;</span><br>
&nbsp; &nbsp; <span class="kw1">for</span> i <span class="kw1">in</span> <span class="kw2">range</span><span class="br0">(</span><span class="kw2">len</span><span class="br0">(</span>a<span class="br0">)</span><span class="br0">)</span>:<br>
&nbsp; &nbsp; &nbsp; &nbsp; x <span class="sy0">=</span> np.<span class="kw3">array</span><span class="br0">(</span><span class="br0">[</span><span class="br0">[</span><span class="nu0">1</span><span class="sy0">,</span> <span class="nu0">0</span><span class="br0">]</span><span class="br0">]</span><span class="br0">)</span><span class="sy0">;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; rot <span class="sy0">=</span> np.<span class="kw3">array</span><span class="br0">(</span><span class="br0">[</span><span class="br0">[</span>np.<span class="me1">cos</span><span class="br0">(</span>a<span class="br0">[</span>i<span class="br0">]</span><span class="br0">)</span><span class="sy0">,</span> -np.<span class="me1">sin</span><span class="br0">(</span>a<span class="br0">[</span>i<span class="br0">]</span><span class="br0">)</span><span class="br0">]</span><span class="sy0">,</span><span class="br0">[</span> np.<span class="me1">sin</span><span class="br0">(</span>a<span class="br0">[</span>i<span class="br0">]</span><span class="br0">)</span><span class="sy0">,</span>np.<span class="me1">cos</span><span class="br0">(</span>a<span class="br0">[</span>i<span class="br0">]</span><span class="br0">)</span><span class="br0">]</span><span class="br0">]</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; xr <span class="sy0">=</span> x.<span class="me1">dot</span><span class="br0">(</span>rot<span class="br0">)</span> <span class="co1"># application de la rotation</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; coord <span class="sy0">=</span> np.<span class="me1">vstack</span><span class="br0">(</span><span class="br0">(</span>coord<span class="sy0">,</span>xr+coord<span class="br0">[</span>-<span class="nu0">1</span><span class="sy0">,</span>:<span class="br0">]</span><span class="br0">)</span><span class="br0">)</span><br>
&nbsp; &nbsp; plt.<span class="me1">plot</span><span class="br0">(</span>coord<span class="br0">[</span>:<span class="sy0">,</span><span class="nu0">0</span><span class="br0">]</span><span class="sy0">,</span>coord<span class="br0">[</span>:<span class="sy0">,</span><span class="nu0">1</span><span class="br0">]</span><span class="br0">)</span><br>
&nbsp; &nbsp; <span class="kw1">return</span><br>
<br>
<span class="co1">#Trois lettres générées pour 5 classes (A -&gt; E)</span><br>
n <span class="sy0">=</span> <span class="nu0">3</span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="co1"># nb d'échantillon par classe</span><br>
nClred <span class="sy0">=</span> <span class="nu0">5</span> &nbsp; <span class="co1"># nb de classes à considérer</span><br>
fig <span class="sy0">=</span> plt.<span class="me1">figure</span><span class="br0">(</span><span class="br0">)</span><br>
<span class="kw1">for</span> cl <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span>nClred<span class="br0">)</span>:<br>
&nbsp; &nbsp; Pic <span class="sy0">=</span> models<span class="br0">[</span>cl<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>.<span class="me1">cumsum</span><span class="br0">(</span><span class="br0">)</span> <span class="co1"># calcul des sommes cumulées pour gagner du temps</span><br>
&nbsp; &nbsp; Ac <span class="sy0">=</span> models<span class="br0">[</span>cl<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span>.<span class="me1">cumsum</span><span class="br0">(</span><span class="nu0">1</span><span class="br0">)</span><br>
&nbsp; &nbsp; Bc <span class="sy0">=</span> models<span class="br0">[</span>cl<span class="br0">]</span><span class="br0">[</span><span class="nu0">2</span><span class="br0">]</span>.<span class="me1">cumsum</span><span class="br0">(</span><span class="nu0">1</span><span class="br0">)</span><br>
&nbsp; &nbsp; <span class="kw2">long</span> <span class="sy0">=</span> np.<span class="me1">floor</span><span class="br0">(</span>np.<span class="kw3">array</span><span class="br0">(</span><span class="br0">[</span><span class="kw2">len</span><span class="br0">(</span>x<span class="br0">)</span> <span class="kw1">for</span> x <span class="kw1">in</span> Xd<span class="br0">[</span>itrain<span class="br0">[</span>cl<span class="br0">]</span><span class="br0">]</span><span class="br0">]</span><span class="br0">)</span>.<span class="me1">mean</span><span class="br0">(</span><span class="br0">)</span><span class="br0">)</span> <span class="co1"># longueur de seq. à générer = moyenne des observations</span><br>
&nbsp; &nbsp; <span class="kw1">for</span> im <span class="kw1">in</span> <span class="kw2">range</span><span class="br0">(</span>n<span class="br0">)</span>:<br>
&nbsp; &nbsp; &nbsp; &nbsp; s<span class="sy0">,</span>x <span class="sy0">=</span> generateHMM<span class="br0">(</span>Pic<span class="sy0">,</span> Ac<span class="sy0">,</span> Bc<span class="sy0">,</span> <span class="kw2">int</span><span class="br0">(</span><span class="kw2">long</span><span class="br0">)</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; intervalle <span class="sy0">=</span> <span class="nu0">360</span>./d &nbsp;<span class="co1"># pour passer des états =&gt; angles</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; newa_continu <span class="sy0">=</span> np.<span class="kw3">array</span><span class="br0">(</span><span class="br0">[</span>i*intervalle <span class="kw1">for</span> i <span class="kw1">in</span> x<span class="br0">]</span><span class="br0">)</span> <span class="co1"># conv int =&gt; double</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; sfig <span class="sy0">=</span> plt.<span class="me1">subplot</span><span class="br0">(</span>nClred<span class="sy0">,</span>n<span class="sy0">,</span>im+n*cl+<span class="nu0">1</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; sfig.<span class="me1">axes</span>.<span class="me1">get_xaxis</span><span class="br0">(</span><span class="br0">)</span>.<span class="me1">set_visible</span><span class="br0">(</span><span class="kw2">False</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; sfig.<span class="me1">axes</span>.<span class="me1">get_yaxis</span><span class="br0">(</span><span class="br0">)</span>.<span class="me1">set_visible</span><span class="br0">(</span><span class="kw2">False</span><span class="br0">)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; tracerLettre<span class="br0">(</span>newa_continu<span class="br0">)</span><br>
plt.<span class="me1">savefig</span><span class="br0">(</span><span class="st0">"lettres_hmm.png"</span><span class="br0">)</span></div></div>
  <div class="sourceblocklink"><a href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=sourceblock&amp;num=4" type="text/plain">[$[Get Code]]</a></div>
</div>

<div class="vspace"></div><div> <img src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/TME7genLettres.png" alt="" title="" width="600px"></div>
<div class="vspace"></div><h2><span style="color: blue;"> Dilemme Biais-Variance, reflexion sur la complexité des modèles</span></h2>
<p>Durant ces deux semaines, on a étudié des modèles de complexités 
croissantes: architecture plus complexe, nombre de paramètres en hausse.
Cela nous amène à discuter le compromis biais-variance.
On considère en général qu'un modèle <em>pauvre</em>:
</p><ul><li>est en général plus loin de la solution optimale {$h^\star$} (grand biais),
</li><li>mais comme l'espace des hypothèses {$\mathcal H$} est peu étendu, les résultats sont relativement stable (faible variance).
</li></ul><div> <img src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/TME7_biais1.png" alt="" title="" width="400px"></div>
<p class="vspace">A l'inverse, un modèle plus <em>riche</em>:
</p><ul><li>peut s'approcher plus près de la solution optimale {$h^\star$} (biais faible),
</li><li>mais présente un problème de stabilité du fait de l'étendue de 
l'espace d'hypothèses {$\mathcal H$} à explorer... (grande variance)
</li></ul><div> <img src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/TME7_biais2.png" alt="" title="" width="400px"></div>
<p class="vspace">Les solutions de régularisation (comme celle proposée 
dans l'algorithme de comptage) cherche à optimiser le compromis, c'est à
 dire à isoler une partie de l'espace des hypothèses {$\mathcal H$} 
particulièrement intéressante:
</p>
<div class="vspace"></div><div> <img src="MAPSI%20Cours_Semaine%207%20TME%207_fichiers/TME7_biais3.png" alt="" title="" width="400px"></div>
<p class="vspace">En faisant tourner plusieurs fois les algorithmes de 
chaines de Markov simples et plusieurs fois les algorithmes de MMC avec 
différentes valeurs de N et K:
</p><ul><li>calculer les moyennes et variances des performances obtenues,
</li><li>analyser les résultats par rapport au compromis biais-variance
</li></ul>
</div>

				</div>
			</div>

			<div id="sidebar">
				<!--PageSearchFmt-->
				<div class="boxy short">
					<div id="search">
						<h3>Search</h3>

						<form id="searchform" action="http://webia.lip6.fr/~mapsi/pmwiki.php" method="get">
						<fieldset>
							<input name="n" value="Cours.Semaine7TME7" type="hidden">
							<input name="action" value="search" type="hidden">
							<input class="searchBox" id="q" name="q" type="text">
							<input class="searchButton" value="Go" type="submit">
						</fieldset>
						</form>
					</div>
				</div>
				<!--/PageSearchFmt-->

				<!--PageRightFmt-->
				<div class="boxy tall">
					<p class="sidehead"> <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Main.TutoPython">Tutoriel numpy</a>
</p>
<p class="vspace sidehead"> <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Main.Salles">Infos Cours/TD/TME</a>
</p>
<p class="vspace sidehead"> <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Main.Annales">Annales</a>
</p>
<p class="vspace sidehead"> Semainier
</p><ul><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine1">Semaine 1</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine2">Semaine 2</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine3">Semaine 3</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine4">Semaine 4</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine5">Semaine 5</a>
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine6">Semaine 6</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7">Semaine 7</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine8">Semaine 8</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine9">Semaine 9</a>  
</li><li><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine10">Semaine 10</a>  
</li></ul><p class="vspace sidehead"> <a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Main.Examen">Infos Examen</a>
</p>
<p class="vspace sidehead"> Liens
</p>
<p class="vspace" style="text-align: right;"> <span style="font-size:83%"><a class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Site.SideBar?action=edit">edit SideBar</a></span>
</p>

				</div>
				<!--/PageRightFmt-->
			</div>
		</div>

		<div id="options-container">
			<!--PageOptionsFmt-->
			<div id="options">
				<h2>Options:</h2>
				<ul id="option_size">
					<li title="size: fixed" id="option_size_fixed" class="fixed"><a><span>fixed</span></a></li>
					<li title="size: fluid" id="option_size_fluid" class="fluid"><a><span>fluid</span></a></li>
				</ul>

				<ul id="option_color">
					<li title="color: orange" id="option_color_orange" class="orange"><a><span>orange</span></a></li>
					<li title="color: blue" id="option_color_blue" class="blue"><a><span>blue</span></a></li>
					<li title="color: green" id="option_color_green" class="green"><a><span>green</span></a></li>
					<li title="color: pink" id="option_color_pink" class="pink"><a><span>pink</span></a></li>
					<li title="color: cyan" id="option_color_cyan" class="cyan"><a><span>cyan</span></a></li>
					<li title="color: red" id="option_color_red" class="red"><a><span>red</span></a></li>
					<li title="color: violet" id="option_color_violet" class="violet"><a><span>violet</span></a></li>
				</ul>
			</div>
			<!--/PageOptionsFmt-->

			<!--PageActionFmt-->
			<div class="pageactions">
				<ul><li class="browse">      <a accesskey="" rel="nofollow" class="selflink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7">View</a>
</li><li class="edit">      <a accesskey="e" rel="nofollow" class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=edit">Edit</a>
</li><li class="diff">   <a accesskey="h" rel="nofollow" class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=diff">History</a>
</li><li class="print">     <a accesskey="" rel="nofollow" class="wikilink" href="http://webia.lip6.fr/%7Emapsi/pmwiki.php?n=Cours.Semaine7TME7?action=print">Print</a>
</li></ul>

			</div>
			<!--/PageActionFmt-->
		</div>

		<div id="footer">
			<!--PageFooterFmt-->
				<div class="footer"><p>Page last modified on November 13, 2015, at 10:19 AM EST
</p>
</div>
			<!--/PageFooterFmt-->
			<p id="credits"><a href="http://evil.che.lu/projects/skittlish">Skittlish</a> theme adapted by <a href="http://solidgone.org/Skins/">David Gilbert</a>, powered by <a href="http://pmwiki.com/">PmWiki</a></p>
		</div>
	</div>
<!--HTMLFooter-->


</body></html>